{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jw3KPqrHOcE"
      },
      "source": [
        "All of the code can be run on Kaggle using a GPU T4. It will take around ~35-50 minutes. After importing the notebook into Kaggle, you can configure the session options on the right hand side. Choose GPU T4 x2 as the accelerator and turn on the Internet so that the pretrained `resnet50` model from PyTorch can be downloaded. \n",
        "\n",
        "This code will output a file called '20898399_Mao.csv' that has the predictions for the test data from my model. This file was submitted to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-08-11T05:06:59.380788Z",
          "iopub.status.busy": "2024-08-11T05:06:59.380356Z",
          "iopub.status.idle": "2024-08-11T05:06:59.876231Z",
          "shell.execute_reply": "2024-08-11T05:06:59.874969Z",
          "shell.execute_reply.started": "2024-08-11T05:06:59.380731Z"
        },
        "id": "q4aaca8X1upD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torchvision.io import read_image\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-11T05:07:16.704706Z",
          "iopub.status.busy": "2024-08-11T05:07:16.703296Z",
          "iopub.status.idle": "2024-08-11T05:07:19.771337Z",
          "shell.execute_reply": "2024-08-11T05:07:19.770121Z",
          "shell.execute_reply.started": "2024-08-11T05:07:16.704667Z"
        },
        "id": "gViuDcga1upD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data(csv_path, img_folder):\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Get ancillary data and targets\n",
        "    ancillary_data = df.iloc[:, 1:164].values  # All variables but 'id'\n",
        "    targets = df.iloc[:, -6:].values\n",
        "\n",
        "    # Get image paths\n",
        "    img_paths = [os.path.join(img_folder, file) for file in os.listdir(img_folder)]\n",
        "\n",
        "    return img_paths, ancillary_data, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48Pb2RVh4Y0u"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "batch_size = 20\n",
        "learning_rate = 0.001\n",
        "decay = 0.0001\n",
        "num_traits = 6\n",
        "num_epochs = 10\n",
        "\n",
        "# Based on https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files\n",
        "class PlantDataset(Dataset):\n",
        "    def __init__(self, img_paths, ancillary_data, targets=None, transform=None):\n",
        "        self.img_paths = img_paths\n",
        "        self.ancillary_data = ancillary_data\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # ancillary = torch.tensor(self.ancillary_data[idx], dtype=torch.float32)\n",
        "\n",
        "        if self.targets is not None:\n",
        "            target = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
        "            return img, target  # , ancillary\n",
        "\n",
        "        return img\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, num_ancillary_features=163):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # ResNet50\n",
        "        self.resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "        self.resnet.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "        features = self.resnet.fc.in_features\n",
        "        # Replace the last layer so that we have 6 output features\n",
        "        # Based on this Medium article: https://medium.com/@lucrece.shin/chapter-3-transfer-learning-with-resnet50-from-dataloaders-to-training-seed-of-thought-67aaf83155bc\n",
        "        self.resnet.fc = nn.Linear(features, num_traits)\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.resnet(img)\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  loss_fn = nn.MSELoss()\n",
        "  model.train()\n",
        "\n",
        "  train_loss = 0\n",
        "  # for img, ancillary, targets in train_loader:\n",
        "  for img, targets in train_loader:\n",
        "    img, targets = img.to(device), targets.to(device)\n",
        "    # img, ancillary, targets = img.to(device), ancillary.to(device), targets.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(img)\n",
        "    # outputs = model(img, ancillary)\n",
        "    loss = loss_fn(output, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  train_loss /= len(train_loader)\n",
        "\n",
        "  print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "  print(f\"Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # for img, ancilliary, _ in test_loader:\n",
        "    for img in test_loader:\n",
        "        # img, ancillary = img.to(device), ancillary.to(device)\n",
        "        img = img.to(device)\n",
        "        # output = model(img, ancillary)\n",
        "        output = model(img)\n",
        "        # From: https://stackoverflow.com/questions/53467215/convert-pytorch-cuda-tensor-to-numpy-array\n",
        "        predictions.append(output.data.cpu().numpy())\n",
        "\n",
        "  predictions = np.concatenate(predictions)\n",
        "  return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VItiGyDZEwXx",
        "outputId": "6abd8bd4-267a-4011-aeed-096dbf44a74b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Train Loss: 24206300968.7192\n",
            "Epoch 2/10\n",
            "Train Loss: 12729432588.2748\n",
            "Epoch 3/10\n",
            "Train Loss: 3170605432.5874\n",
            "Epoch 4/10\n",
            "Train Loss: 886845.3305\n",
            "Epoch 5/10\n",
            "Train Loss: 875169.5243\n",
            "Epoch 6/10\n",
            "Train Loss: 870512.9747\n",
            "Epoch 7/10\n",
            "Train Loss: 868128.0026\n",
            "Epoch 8/10\n",
            "Train Loss: 865889.6672\n",
            "Epoch 9/10\n",
            "Train Loss: 865923.6844\n",
            "Epoch 10/10\n",
            "Train Loss: 858672.6913\n"
          ]
        }
      ],
      "source": [
        "# Load Data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # Convert PIL Image to Tensor\n",
        "])\n",
        "\n",
        "train_imgs, train_ancillary, train_targets = load_and_preprocess_data(\n",
        "    \"/kaggle/input/cs-480-2024-spring/data/train.csv\",\n",
        "    \"/kaggle/input/cs-480-2024-spring/data/train_images\",\n",
        ")\n",
        "\n",
        "training_data = PlantDataset(train_imgs, train_ancillary, train_targets, transform)\n",
        "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_imgs, test_ancillary, _ = load_and_preprocess_data(\n",
        "    \"/kaggle/input/cs-480-2024-spring/data/test.csv\",\n",
        "    \"/kaggle/input/cs-480-2024-spring/data/test_images\"\n",
        ")\n",
        "\n",
        "test_data = PlantDataset(test_imgs, test_ancillary, transform=transform)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "# Intialize model\n",
        "model = Model().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=decay)\n",
        "\n",
        "# Start training\n",
        "for epoch in range(num_epochs):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "\n",
        "# Test it and output predictions into CSV file\n",
        "predictions = test(model, device, test_loader)\n",
        "\n",
        "# Create submission file\n",
        "predictions_df = pd.DataFrame({\n",
        "    'id': pd.read_csv('/kaggle/input/cs-480-2024-spring/data/test.csv')[\"id\"],\n",
        "    'X4': predictions[:, 0],\n",
        "    'X11': predictions[:, 1],\n",
        "    'X18': predictions[:, 2],\n",
        "    'X26': predictions[:, 3],\n",
        "    'X50': predictions[:, 4],\n",
        "    'X3112': predictions[:, 5]\n",
        "})\n",
        "\n",
        "predictions_df.to_csv('20898399_Mao.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 8915386,
          "sourceId": 81655,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30746,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
